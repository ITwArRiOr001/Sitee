{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ITwArRiOr001/Sitee/blob/main/NLPFakenewsAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“¦ Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# âœ… Step 1: Preprocessing (using 'text' column)\n",
        "X = df['text']\n",
        "y = df['label']  # 1 = Real, 0 = Fake\n",
        "\n",
        "# âœ… Step 2: Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# âœ… Step 3: TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# âœ… Step 4: Train model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# âœ… Step 5: Evaluate\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# âœ… Step 6: Save model\n",
        "joblib.dump(model, \"news_fake_model.pkl\")\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
        "\n",
        "# âœ… Step 7: Predict (local ML)\n",
        "def predict_news(text):\n",
        "    model = joblib.load(\"news_fake_model.pkl\")\n",
        "    vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
        "    features = vectorizer.transform([text])\n",
        "    pred = model.predict(features)[0]\n",
        "    return \"REAL\" if pred == 1 else \"FAKE\"\n",
        "\n",
        "# âœ… Step 8: Web-Based Semantic Verifier (NewsAPI)\n",
        "NEWS_API_KEY = \"your_newsapi_key_here\"  # ðŸ”‘ Replace with your NewsAPI key\n",
        "semantic_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "def search_news_articles(query):\n",
        "    url = f\"https://newsapi.org/v2/everything?q={query}&language=en&pageSize=5&sortBy=relevancy&apiKey={NEWS_API_KEY}\"\n",
        "    res = requests.get(url)\n",
        "    data = res.json()\n",
        "    return [f\"{a['title']}. {a['description']}\" for a in data.get(\"articles\", []) if a['description']]\n",
        "\n",
        "def web_verify_claim(text):\n",
        "    articles = search_news_articles(text)\n",
        "    if not articles:\n",
        "        return {\"verdict\": \"UNVERIFIED\", \"reason\": \"No article found\", \"evidence\": []}\n",
        "\n",
        "    input_embedding = semantic_model.encode(text, convert_to_tensor=True)\n",
        "    article_embeddings = semantic_model.encode(articles, convert_to_tensor=True)\n",
        "\n",
        "    sim_scores = util.pytorch_cos_sim(input_embedding, article_embeddings)[0]\n",
        "    best_idx = int(sim_scores.argmax())\n",
        "    top_score = float(sim_scores[best_idx])\n",
        "\n",
        "    if top_score > 0.75:\n",
        "        return {\n",
        "            \"verdict\": \"REAL\",\n",
        "            \"confidence\": round(top_score, 3),\n",
        "            \"reason\": \"Matched real source\",\n",
        "            \"evidence\": [articles[best_idx]]\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            \"verdict\": \"UNVERIFIED\",\n",
        "            \"confidence\": round(top_score, 3),\n",
        "            \"reason\": \"Low similarity to known sources\",\n",
        "            \"evidence\": articles\n",
        "        }\n",
        "\n",
        "# âœ… Step 9: Unified checker\n",
        "def unified_news_check(text):\n",
        "    model_result = predict_news(text)\n",
        "    web_result = web_verify_claim(text)\n",
        "    return {\n",
        "        \"local_model_verdict\": model_result,\n",
        "        \"web_verifier_verdict\": web_result[\"verdict\"],\n",
        "        \"reason\": web_result[\"reason\"],\n",
        "        \"confidence\": web_result.get(\"confidence\"),\n",
        "        \"evidence\": web_result.get(\"evidence\")\n",
        "    }\n",
        "\n",
        "# âœ… Step 10: Example test\n",
        "if __name__ == \"__main__\":\n",
        "    sample = \"Iran and Israel is at War\"\n",
        "    result = unified_news_check(sample)\n",
        "    print(\"[RESULT]\", json.dumps(result, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ8URtRQ4REN",
        "outputId": "4efb413f-3914-43f5-d495-8ecd67d51e47"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99      4708\n",
            "           1       0.98      0.99      0.98      4272\n",
            "\n",
            "    accuracy                           0.99      8980\n",
            "   macro avg       0.99      0.99      0.99      8980\n",
            "weighted avg       0.99      0.99      0.99      8980\n",
            "\n",
            "[RESULT] {\n",
            "  \"local_model_verdict\": \"FAKE\",\n",
            "  \"web_verifier_verdict\": \"UNVERIFIED\",\n",
            "  \"reason\": \"No article found\",\n",
            "  \"confidence\": null,\n",
            "  \"evidence\": []\n",
            "}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}